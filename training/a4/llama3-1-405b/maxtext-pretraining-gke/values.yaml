# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

queue:

dwsSettings:
  maxRunDurationSeconds:

tasSettings:
  topologyRequest:
    kueue.x-k8s.io/podset-preferred-topology: "kubernetes.io/hostname"

volumes:
  gcsVolumes: false
  psVolumes: false

workload:
  gpus: 256 # This should be one of: {<= 8,  multiple of 8}
  image: us-central1-docker.pkg.dev/deeplearning-images/reproducibility/jax-maxtext-gpu:jax0.5.1-cuda_dl25.02-rev1-maxtext-20150317
  configFile: maxtext-config.yaml
  configPath: /workload/configs
  defaultArguments:
  - steps=15
  arguments[]:
  envs:
  - name: MAXTEXT_CONFIG_PATH
    value: "/workload/configs/maxtext-config.yaml"
  - name: TF_CPP_VMODULE
    value: "profile_guided_latency_estimator=10"
  - name: TF_CPP_MIN_LOG_LEVEL
    value: "0"
  - name: TF_CPP_MAX_LOG_LEVEL
    value: "100"
  - name: XLA_PYTHON_CLIENT_MEM_FRACTION
    value: "0.98"
  - name: CUDA_DEVICE_MAX_CONNECTIONS
    value: "1"
  - name: NVTE_FUSED_ATTN
    value: "1"
  - name: JAX_REMOVE_CUSTOM_PARTITIONING_PTR_FROM_CACHE_KEY
    value: "true"
  - name: JAX_ENABLE_PGLE
    value: "false"
  - name: JAX_ENABLE_COMPILATION_CACHE
    value: "false"
  - name: XLA_FLAGS
    value: >-
      --xla_gpu_enable_latency_hiding_scheduler=true
      --xla_gpu_enable_triton_gemm=false
      --xla_gpu_enable_command_buffer=FUSION,CUSTOM_CALL
      --xla_gpu_all_reduce_combine_threshold_bytes=17179869184
      --xla_gpu_all_gather_combine_threshold_bytes=17179869184
      --xla_gpu_reduce_scatter_combine_threshold_bytes=17179869184
      --xla_gpu_enable_pipelined_all_gather=true
      --xla_gpu_enable_pipelined_reduce_scatter=true
      --xla_gpu_enable_pipelined_all_reduce=true
      --xla_gpu_enable_while_loop_double_buffering=true
      --xla_gpu_enable_all_gather_combine_by_dim=false
      --xla_gpu_enable_reduce_scatter_combine_by_dim=false
      --xla_disable_hlo_passes=rematerialization

network:
  hostNetwork: True
  gibVersion: us-docker.pkg.dev/gce-ai-infra/gpudirect-gib/nccl-plugin-gib:v1.0.5
  subnetworks[]:
  ncclSettings:
  - name: NCCL_DEBUG
    value: "VERSION"

