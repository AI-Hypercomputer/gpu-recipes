# Pretrain Mixtral-8x7B workloads on A4 GKE Node pools with Nvidia NeMo Framework

This recipe outlines the steps for running a Mixtral 8x7B pretraining workload on
[A4 GKE Node pools](https://cloud.google.com/kubernetes-engine) by using the
[NVIDIA NeMo framework](https://github.com/NVIDIA/nemo).

## Orchestration and deployment tools

For this recipe, the following setup is used:

- Orchestration - [Google Kubernetes Engine (GKE)](https://cloud.google.com/kubernetes-engine)
- Pretraining job configuration and deployment - A Helm chart is used to configure and deploy
  the [Kubernetes Jobset](https://kubernetes.io/blog/2025/03/23/introducing-jobset)
  resource which manages the execution  of the
  [NeMo pretraining workload](https://github.com/NVIDIA-NeMo/NeMo/blob/v2.4.0/examples/nlp/language_modeling/megatron_gpt_pretraining.py).

## Test environment

This recipe has been optimized for and tested with the following configuration:

- GKE cluster
    - [A regional standard cluster](https://cloud.google.com/kubernetes-engine/docs/concepts/configuration-overview) version: 1.32.4-gke.1236000 or later.
    - A GPU node pool with 2, 4, 32, 64 or 128
    [a4-highgpu-8g](https://cloud.google.com/compute/docs/accelerator-optimized-machines#a4-high-vms) provisioned using the DENSE deployment type.
    - [Workload Identity Federation for GKE](https://cloud.google.com/kubernetes-engine/docs/concepts/workload-identity) enabled.
    - [Cloud Storage FUSE CSI driver for GKE](https://cloud.google.com/kubernetes-engine/docs/concepts/cloud-storage-fuse-csi-driver) enabled.
    - [DCGM metrics](https://cloud.google.com/kubernetes-engine/docs/how-to/dcgm-metrics) enabled.
    - [Kueue](https://kueue.sigs.k8s.io/docs/reference/kueue.v1beta1/) and [JobSet](https://jobset.sigs.k8s.io/docs/overview/) APIs installed.
    - Kueue configured to support [Topology Aware Scheduling](https://kueue.sigs.k8s.io/docs/concepts/topology_aware_scheduling/).
- A regional Google Cloud Storage (GCS) bucket to store logs generated by the recipe runs.

To prepare the required environment, see
[GKE environment setup guide](../../../../docs/configuring-environment-gke-a4.md).

## Training dataset

This recipe uses a mock pretraining dataset provided by the NeMo framework

## Docker container image

This recipe uses the following [Deep Learning Software Layer](https://cloud.google.com/ai-hypercomputer/docs/software-stack#cluster_images) container image:

`us-central1-docker.pkg.dev/deeplearning-images/reproducibility/pytorch-gpu-nemo-nccl:nemo25.02-gib1.0.5-A4`.

This image is based on NVIDIA NeMo 25.02 and contains the NCCL gIB plugin v1.0.5, bundling all NCCL binaries validated for use with A4 GPUs.


## Run the recipe

From your client workstation, complete the following steps:

### Configure environment settings

Set the environment variables to match your environment:

 ```bash
 export PROJECT_ID=<PROJECT_ID>
 export CLUSTER_REGION=<CLUSTER_REGION>
 export CLUSTER_NAME=<CLUSTER_NAME>
 export GCS_BUCKET=<GCS_BUCKET>
 export KUEUE_NAME=<KUEUE_NAME>
 ```

Replace the following values:

 - `<PROJECT_ID>`: your Google Cloud project ID.
 - `<CLUSTER_REGION>`: the region where your cluster is located.
 - `<CLUSTER_NAME>`: the name of your GKE cluster.
 - `<GCS_BUCKET>`: the name of your Cloud Storage bucket. Don't include the `gs://` prefix.
 - `<KUEUE_NAME>`: the name of the Kueue local queue. The default queue created by the cluster toolkit is `a4`. Make sure to verify the name of the local queue in your cluster.

Set the default project:

 ```bash
 gcloud config set project $PROJECT_ID
 ```

### Get the recipe

Clone the `gpu-recipes` repository and set a reference to the recipe folder.

```
git clone https://github.com/ai-hypercomputer/gpu-recipes.git
cd gpu-recipes
export REPO_ROOT=`git rev-parse --show-toplevel`
export RECIPE_ROOT=$REPO_ROOT/training/a4/mixtral-8x7b/nemo-pretraining-gke
cd $RECIPE_ROOT
```

### Get cluster credentials

```
gcloud container clusters get-credentials $CLUSTER_NAME --region $CLUSTER_REGION
```

### Configure and submit a pretraining job

#### Using 32 nodes (256 GPUs) FP8

The default job setting is 50 training steps and fp8 precision. To execute the job with the
default settings, run the following command from your client:

```bash
helm  install -f $RECIPE_ROOT/values.yaml \
    --set-file workload_launcher=$REPO_ROOT/src/launchers/nemo-10-launcher.sh \
    --set-file workload_config=$REPO_ROOT/src/frameworks/a4/nemo-configs/mixtral-8x7b-256gpus-a4-fp8.yaml \
    --set queue=${KUEUE_NAME} \
    --set volumes.gcsMounts[0].bucketName=${GCS_BUCKET} \
    $USER-mixtral-8x7b-nemo \
    $REPO_ROOT/src/helm-charts/a4/jobset
```

#### Using 32 nodes (256 GPUs) BF16

The default job setting is 50 training steps and bf16 precision. To execute the job with the
default settings, run the following command:

```bash
helm  install -f $RECIPE_ROOT/values.yaml \
    --set-file workload_launcher=$REPO_ROOT/src/launchers/nemo-10-launcher.sh \
    --set-file workload_config=$REPO_ROOT/src/frameworks/a4/nemo-configs/mixtral-8x7b-256gpus-a4-bf16.yaml \
    --set queue=${KUEUE_NAME} \
    --set volumes.gcsMounts[0].bucketName=${GCS_BUCKET} \
    $USER-mixtral-8x7b-nemo \
    $REPO_ROOT/src/helm-charts/a4/jobset
```

#### Using 4 nodes (32 GPUs) FP8

The default job setting is 50 training steps and fp8 precision. To execute the job with the
default settings, run the following command:

```bash
helm  install -f $RECIPE_ROOT/values.yaml \
    --set-file workload_launcher=$REPO_ROOT/src/launchers/nemo-10-launcher.sh \
    --set-file workload_config=$REPO_ROOT/src/frameworks/a4/nemo-configs/mixtral-8x7b-16-32-gpus-a4-fp8.yaml \
    --set queue=${KUEUE_NAME} \
    --set volumes.gcsMounts[0].bucketName=${GCS_BUCKET} \
    --set workload.gpus=32 \
    $USER-mixtral-8x7b-nemo \
    $REPO_ROOT/src/helm-charts/a4/jobset
```

#### Using 4 nodes (32 GPUs) BF16

The default job setting is 50 training steps and bf16 precision. To execute the
job with the default settings, run the following command from your client:

```bash
helm  install -f $RECIPE_ROOT/values.yaml \
    --set-file workload_launcher=$REPO_ROOT/src/launchers/nemo-10-launcher.sh \
    --set-file workload_config=$REPO_ROOT/src/frameworks/a4/nemo-configs/mixtral-8x7b-16-32-gpus-a4-bf16.yaml \
    --set queue=${KUEUE_NAME} \
    --set volumes.gcsMounts[0].bucketName=${GCS_BUCKET} \
    --set workload.gpus=32 \
    $USER-mixtral-8x7b-nemo \
    $REPO_ROOT/src/helm-charts/a4/jobset
```

#### Using 2 nodes (16 GPUs) FP8

The default job setting is 50 training steps and fp8 precision. To execute the job with the
default settings, run the following command:

```bash
helm  install -f $RECIPE_ROOT/values.yaml \
    --set-file workload_launcher=$REPO_ROOT/src/launchers/nemo-10-launcher.sh \
    --set-file workload_config=$REPO_ROOT/src/frameworks/a4/nemo-configs/mixtral-8x7b-16-32-gpus-a4-fp8.yaml \
    --set queue=${KUEUE_NAME} \
    --set volumes.gcsMounts[0].bucketName=${GCS_BUCKET} \
    --set workload.gpus=16 \
    $USER-mixtral-8x7b-nemo \
    $REPO_ROOT/src/helm-charts/a4/jobset
```

#### Using 2 nodes (16 GPUs) BF16

The default job setting is 50 training steps and bf16 precision. To execute the
job with the default settings, run the following command from your client:

```bash
helm  install -f $RECIPE_ROOT/values.yaml \
    --set-file workload_launcher=$REPO_ROOT/src/launchers/nemo-10-launcher.sh \
    --set-file workload_config=$REPO_ROOT/src/frameworks/a4/nemo-configs/mixtral-8x7b-16-32-gpus-a4-bf16.yaml \
    --set queue=${KUEUE_NAME} \
    --set volumes.gcsMounts[0].bucketName=${GCS_BUCKET} \
    --set workload.gpus=16 \
    $USER-mixtral-8x7b-nemo \
    $REPO_ROOT/src/helm-charts/a4/jobset
```

#### Using 64 nodes (512 GPUs) FP8

The default job setting is 30 training steps and fp8 precision. To execute the
job with the default settings, run the following command from your client:

```bash
helm  install -f $RECIPE_ROOT/values.yaml \
    --set-file workload_launcher=$REPO_ROOT/src/launchers/nemo-10-launcher.sh \
    --set-file workload_config=$REPO_ROOT/src/frameworks/a4/nemo-configs/mixtral-8x7b-512gpus-a4-fp8.yaml \
    --set queue=${KUEUE_NAME} \
    --set volumes.gcsMounts[0].bucketName=${GCS_BUCKET} \
    --set workload.gpus=512 \
    $USER-mixtral-8x7b-nemo \
    $REPO_ROOT/src/helm-charts/a4/jobset
```

#### Using 128 nodes (1024 GPUs) FP8

The default job setting is 30 training steps and fp8 precision. To execute the
job with the default settings, run the following command from your client:

```bash
helm  install -f $RECIPE_ROOT/values.yaml \
    --set-file workload_launcher=$REPO_ROOT/src/launchers/nemo-10-launcher.sh \
    --set-file workload_config=$REPO_ROOT/src/frameworks/a4/nemo-configs/mixtral-8x7b-1024gpus-a4-fp8.yaml \
    --set queue=${KUEUE_NAME} \
    --set volumes.gcsMounts[0].bucketName=${GCS_BUCKET} \
    --set workload.gpus=1024 \
    $USER-mixtral-8x7b-nemo \
    $REPO_ROOT/src/helm-charts/a4/jobset
```

#### Configure job settings

You can overwrite any of the default
[NeMo configurations](../../../../src/frameworks/a4/nemo-configs/mixtral-8x7b-256gpus-a4-fp8.yaml)
for this job. To do this, we can set the new arguments using `--set workload.arguments`.

**Examples**

-   To set the number of training steps to 100, run the following command from
    your client:

    ```bash
    helm  install -f $RECIPE_ROOT/values.yaml \
        --set-file workload_launcher=$REPO_ROOT/src/launchers/nemo-10-launcher.sh \
        --set-file workload_config=$REPO_ROOT/src/frameworks/a4/nemo-configs/mixtral-8x7b-256gpus-a4-fp8.yaml \
        --set queue=${KUEUE_NAME} \
        --set volumes.gcsMounts[0].bucketName=${GCS_BUCKET} \
        --set workload.arguments[0]="trainer.max_steps=100" \
        $USER-mixtral-8x7b-nemo \
        $REPO_ROOT/src/helm-charts/a4/jobset
    ```

### Monitor the job

To check the status of pods in your job, run the following command:

```
kubectl get pods | grep JOB_NAME_PREFIX
```

Replace the following:
- JOB_NAME_PREFIX - your job name prefix. For example $USER-mixtral-8x7b-nemo.

To get the logs for one of the pods, run the following command:

```
kubectl logs POD_NAME
```

Information about the training job's progress, including crucial details such as loss,
step count, and step time, is generated by the rank 0 process.
This process runs on the pod whose name begins with `JOB_NAME_PREFIX-workload-0-0`.
For example: `user-mixtral-8x7b-nemo-workload-0-0-s9zrv`.


### Troubleshooting

This section provides guidance on troubleshooting issues with the training job.

To check the status of the job's pods, use the following command:

```bash
kubectl get pods | grep JOB_NAME_PREFIX
```

Replace `JOB_NAME_PREFIX` with the prefix of your job name. For example, `$USER-mixtral-8x7b-nemo`. This command will list all pods associated with the specified job, along with their current status.


To get the logs from a specific pod, use the following command:

```bash
kubectl logs POD_NAME
```

Replace `POD_NAME` with the name of the pod you want to inspect.

In this recipe, the training job is orchestrated by the [Kubernetes JobSet](https://jobset.sigs.k8s.io/docs/overview/). If the JobSet encounters a fatal failure, it removes all pods, making it impossible to inspect their logs directly. To analyze logs from a failed job, retrieve them from Cloud Logging using the following filter:

```
resource.type="k8s_container"
resource.labels.project_id="PROJECT_ID"
resource.labels.location="CLUSTER_REGION"
resource.labels.cluster_name="CLUSTER_NAME"
resource.labels.namespace_name="default"
resource.labels.pod_name=~"^JOB_NAME_PREFIX.*"
severity>=DEFAULT
```

Replace the following:
- `PROJECT_ID`: your Google Cloud project ID.
- `CLUSTER_REGION`: the region where your cluster is located.
- `CLUSTER_NAME`: the name of your GKE cluster.
- `JOB_NAME_PREFIX`: the prefix of your job name (e.g., `$USER-mixtral-8x7b-nemo`).

This filter will retrieve logs from all containers within pods that match the job with the specified name prefix.


### Uninstall the Helm release

You can delete the job and other resources created by the Helm chart.
To uninstall Helm, run the following command from your client:

```bash
helm uninstall $USER-mixtral-8x7b-nemo
```

