<!-- mdformat global-off -->
# Pretrain Llama 3 70B workloads on A3U Slurm Cluster with Nvidia Megatron-Bridge

This recipe outlines the steps for running a Llama 3 70B pretraining workload on [Google Cloud A3U Slurm clusters](https://docs.cloud.google.com/ai-hypercomputer/docs/create/create-slurm-cluster) by using [NVIDIA Megatron-Bridge](https://github.com/NVIDIA-NeMo/Megatron-Bridge).

## Orchestration and deployment tools

For this recipe, the following setup is used:

- Orchestration - [Slurm Workload Manager](https://slurm.schedmd.com/)
- Deployment - [Cluster Toolkit](https://cloud.google.com/cluster-toolkit/docs/overview)

## Test environment

This recipe has been optimized for and tested with the following configuration:

- A3U Slurm Cluster (8 nodes, 64 GPUs)
- Machine Type: `a3-ultragpu-8g`
- Lustre Filesystem

Please follow the instructions in the [Cluster Toolkit A3U Example README](https://github.com/GoogleCloudPlatform/cluster-toolkit/blob/main/examples/machine-learning/a3-ultragpu-8g) to provision an A3 ultra Slurm cluster.

## Docker container image

This recipe uses the following container images:

- `nvcr.io/nvidia/nemo:25.09`

## Run the recipe

From your cluster login node, complete the following steps:

### Configure environment settings

#### Setup Enroot for Megatron

We recommend setting this up on Lustre.

```bash
 # Here, /home is a lustre filesystem
export BASE_DIR=/home/${USER}
export LOCAL_SSD_DIR=/mnt/localssd
cd ${BASE_DIR}

# Configure Enroot
export ENROOT_CONFIG_PATH=${HOME}/.config/enroot
mkdir -p ${ENROOT_CONFIG_PATH}

# Authenticate with Google Cloud Docker registry
gcloud auth configure-docker us-docker.pkg.dev

# Import the NVIDIA NeMo container
mkdir -p ${BASE_DIR}/sqsh
enroot import --output ${BASE_DIR}/sqsh/nvidia+nemo+25.09.sqsh -- docker://nvcr.io#nvidia/nemo:25.09
```

### Get the recipe

Clone the Megatron-Bridge repository:

```bash
cd ${BASE_DIR}
git clone https://github.com/NVIDIA-NeMo/Megatron-Bridge.git
cd Megatron-Bridge
git checkout minor_cfg_updates_2509
```

### Configure and submit a pretraining job

#### Using 8 nodes (64 GPUs) FP8 precision

The `submit.slurm` script is provided to run the training job. Ensure you are in your `${BASE_DIR}` and copy/create the `submit.slurm` script there.

Create a logs directory to store the job output:

```bash
mkdir -p ${BASE_DIR}/logs
```

To execute the job with the default settings, run the following command:

```bash
sbatch -p <partition> ${BASE_DIR}/submit.slurm
```


### Monitor the job

To check the status of jobs in your queue, run the following command:

```bash
squeue
```

To view the output logs, use `tail` on the output file generated by Slurm (replace `<JOB_ID>` with your actual job ID):

```bash
tail -f logs/<JOB_NAME>_<USER>_<JOB_ID>.out
```

### Cancel the job

To cancel a running job:

```bash
scancel <JOB_ID>
```
