dwsSettings:
  maxRunDurationSeconds: null
network:
  gibVersion: us-docker.pkg.dev/gce-ai-infra/gpudirect-gib/nccl-plugin-gib-arm64:v1.0.7
  hostNetwork: true
  ncclSettings:
  - name: NCCL_DEBUG
    value: VERSION
  - name: NCCL_ALGO
    value: "Ring,Tree"
  - name: NCCL_NET_GDR_LEVEL
    value: PIX
  - name: NCCL_NET_GDR_C2C
    value: "1"
  - name: NCCL_P2P_NET_CHUNKSIZE
    value: "2097152"
  - name: NCCL_NVLS_ENABLE
    value: "0"
  subnetworks[]: null
queue: null
targetNodepools: null
tasSettings:
  topologyRequest:
    kueue.x-k8s.io/podset-preferred-topology: kubernetes.io/hostname
volumes:
  gcsMounts:
  - bucketName: null
    mountPath: null
  gcsVolumes: true
  psVolumes: false
  ssdMountPath: "/ssd"
workload:
  nodeSelector:
    cloud.google.com/gke-accelerator: nvidia-gb200
  arguments[]: null
  configFile: llama3-1-405b-fp8cs-gbs2048-gpus64.py
  configPath: /workload/configs/
  defaultArguments:
  - --account=none
  - --partition=none
  - --gpu=gb200
  - --num_gpus=64
  - --compute_dtype=fp8
  - --fp8_recipe=cs
  - --global_batch_size=2048
  - --max_steps=30
  - --micro_batch_size=1
  - --tensor_parallel_size=2
  - --context_parallel_size=1
  - --expert_parallel_size=1
  - --expert_tensor_parallel_size=1
  - --pipeline_parallel_size=1
  - --virtual_pipeline_parallel_size=1
  - --use_mcore_fsdp=1
  - --cuda_graphs=0
  - --activation_offload_layers=95
  - --log_dir=/job-logs/nemo-logs
  envs:
  - name: ARTIFACT_DIR
    value: null
  - name: PL_TORCH_DISTRIBUTED_BACKEND
    value: "nccl"
  - name: GLOO_SOCKET_IFNAME
    value: eth0
  - name: TORCH_NCCL_HIGH_PRIORITY
    value: "1"
  - name: NEMO_LAUNCH_SCRIPT
    value: /workload/configs/llama3-1-405b-fp8cs-gbs2048-gpus64.py
  gpus: 64
  image: nvcr.io/nvidia/nemo:25.07
