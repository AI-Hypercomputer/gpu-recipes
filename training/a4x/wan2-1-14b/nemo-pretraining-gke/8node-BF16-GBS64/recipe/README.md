<!-- mdformat global-off -->
# Pretrain wan2-1-14b-fp8cs-gbs64-gpus32 workloads on a4x GKE Node pools with NVIDIA NeMo Megatron-Bridge

This recipe outlines the steps for running a wan2-1-14b-fp8cs-gbs64-gpus32 pretraining workload on a4x GKE Node pools by using the NVIDIA NeMo Megatron-Bridge.

## Orchestration and deployment tools

For this recipe, the following setup is used:

- Orchestration - [Google Kubernetes Engine (GKE)](https://cloud.google.com/kubernetes-engine)
- Pretraining job configuration and deployment - A Helm chart is used to configure and deploy the Kubernetes Jobset resource which manages the execution of the DFM pretraining workload.

## Test environment

This recipe has been optimized for and tested with the following configuration:

- GKE cluster: Please follow Cluster Toolkit [instructions](https://github.com/GoogleCloudPlatform/cluster-toolkit/tree/main/examples/gke-a4x) to create your a4x GKE cluster.
- Node Configuration: 8 nodes (4 GPUs per node, 32 GPUs total).
- GPU Architecture: NVIDIA Blackwell (Grace-Blackwell).

## Training dataset

This recipe uses a mock pretraining dataset. To support long-duration stress testing, the recipe includes a patch to the WanMockDataModule via sed within the launcher to extend the mock data length from 1,024 to effectively infinite (10^12 tokens).

## Docker container image

This recipe uses the following docker images:

- `nvcr.io/nvidia/nemo:25.11.00`
- `us-docker.pkg.dev/gce-ai-infra/gpudirect-gib/nccl-plugin-gib-arm64:v1.1.0`

## Run the recipe

From your client workstation, complete the following steps:

### Configure environment settings

Set the environment variables to match your environment:

```bash
export PROJECT_ID=<PROJECT_ID>
export CLUSTER_REGION=<CLUSTER_REGION>
export CLUSTER_NAME=<CLUSTER_NAME>
export GCS_BUCKET=<GCS_BUCKET> # Note: path should not be prefixed with gs://
export KUEUE_NAME=<KUEUE_NAME>
```

Replace the following values:

- `<PROJECT_ID>`: your Google Cloud project ID.
- `<CLUSTER_REGION>`: the region where your cluster is located.
- `<CLUSTER_NAME>`: the name of your GKE cluster.
- `<GCS_BUCKET>`: the name of your Cloud Storage bucket. Don't include the gs:// prefix.
- `<KUEUE_NAME>`: the name of the Kueue local queue. The default queue created by the cluster toolkit is a4x.

Set the default project:

```bash
gcloud config set project $PROJECT_ID
```

### Get cluster credentials

```bash
gcloud container clusters get-credentials $CLUSTER_NAME --region $CLUSTER_REGION
```

### Get the recipe

Clone the `gpu-recipes` repository and set a reference to the recipe folder.

```
git clone https://github.com/ai-hypercomputer/gpu-recipes.git
cd gpu-recipes
export REPO_ROOT=`git rev-parse --show-toplevel`
export RECIPE_ROOT=$REPO_ROOT/training/a4x/wan2-1-14b/nemo-pretraining-gke/8node-BF16-GBS64/recipe
cd $RECIPE_ROOT
```

### Configure and submit a pretraining job

#### Using 8 nodes (32 gpus) fp8 precision

To execute the job with the default settings, run the following command from your client:

```bash
cd $RECIPE_ROOT
export WORKLOAD_NAME=$USER-a4x-wan2-1-14b-8node
helm install $WORKLOAD_NAME . -f values.yaml \
--set-file workload_launcher=launcher.sh \
--set workload.image=nvcr.io/nvidia/nemo:25.11.00 \
--set volumes.gcsMounts[0].bucketName=${GCS_BUCKET} \
--set volumes.gcsMounts[0].mountPath=/job-logs \
--set workload.envs[0].value=/job-logs/$WORKLOAD_NAME \
--set queue=${KUEUE_NAME}
```

**Examples**

-   To set the number of training steps to 100, run the following command from
    your client:

    ```bash
    cd $RECIPE_ROOT
    export WORKLOAD_NAME=$USER-a4x-wan2-1-14b-8node
    helm install $WORKLOAD_NAME . -f values.yaml \
    --set-file workload_launcher=launcher.sh \
    --set workload.image=nvcr.io/nvidia/nemo:25.11.00 \
    --set volumes.gcsMounts[0].bucketName=${GCS_BUCKET} \
    --set volumes.gcsMounts[0].mountPath=/job-logs \
    --set workload.envs[0].value=/job-logs/$WORKLOAD_NAME \
    --set queue=${KUEUE_NAME} \
    --set workload.arguments[0]="train.train_iters=100"
    ```

### Monitor the job

To check the status of pods in your job, run the following command:

```
kubectl get pods | grep $USER-a4x-wan2-1-14b-8node
```

Replace the following:

- JOB_NAME_PREFIX - your job name prefix. For example $USER-a4x-wan2-1-14b-8node.

To get the logs for one of the pods, run the following command:

```
kubectl logs POD_NAME
```

Information about the training job's progress, including crucial details such as
loss, step count, and step time, is generated by the rank 0 process.
This process runs on the pod whose name begins with
`JOB_NAME_PREFIX-workload-0-0`.
For example: `$USER-a4x-wan2-1-14b-8node-workload-0-0-s9zrv`.

### Uninstall the Helm release

You can delete the job and other resources created by the Helm chart. To
uninstall Helm, run the following command from your client:

```bash
helm uninstall $USER-a4x-wan2-1-14b-8node
```
