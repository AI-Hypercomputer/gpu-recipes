# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

{{ $nodes := div .Values.job.gpus 8 | max 1 }}
{{ $gpusPerNode := min .Values.job.gpus 8 }}

{{- $root := . -}}

apiVersion: leaderworkerset.x-k8s.io/v1
kind: LeaderWorkerSet
metadata:
  name: {{ .Release.Name }}
spec:
  replicas: {{ .Values.sglang.replicaCount }}
  leaderWorkerTemplate:
    size: {{ div (mul .Values.model.tp_size .Values.model.pp_size) $gpusPerNode }}
    restartPolicy: RecreateGroupOnPodRestart
    leaderTemplate:
      metadata:
        labels:
          role: leader
          app: {{ .Release.Name }}
        annotations:
          gke-gcsfuse/volumes: "true"
          gke-gcsfuse/cpu-limit: "0"
          gke-gcsfuse/memory-limit: "0"
          gke-gcsfuse/ephemeral-storage-limit: "0"
          devices.gke.io/container.tcpxo-daemon: |+
            - path: /dev/nvidia0
            - path: /dev/nvidia1
            - path: /dev/nvidia2
            - path: /dev/nvidia3
            - path: /dev/nvidia4
            - path: /dev/nvidia5
            - path: /dev/nvidia6
            - path: /dev/nvidia7
            - path: /dev/nvidiactl
            - path: /dev/nvidia-uvm
            - path: /dev/dmabuf_import_helper
          networking.gke.io/default-interface: "eth0"
          networking.gke.io/interfaces: |
          {{- if $root.Values.network.subnetworks }}
            [
              {{- range $i, $subnetwork := $root.Values.network.subnetworks }}
              {"interfaceName":"eth{{ $i }}","network":"{{ $subnetwork }}"}{{ eq $i 8 | ternary "" ","}}
              {{- end }}
            ]
          {{- else }}
            [
              {"interfaceName":"eth0","network":"default"},
              {{- range  $i := until 8 }}
              {"interfaceName":"eth{{ add 1 $i }}","network":"{{ $root.Values.clusterName }}-gpunet-{{ $i }}-subnet"}{{ eq $i 7 | ternary "" ","}}
              {{- end }}
            ]
          {{- end}}
      spec:
        subdomain: "{{.Release.Name}}"
        restartPolicy: Always
        {{ if $root.Values.targetNodes }}
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: kubernetes.io/hostname
                  operator: In
                  values:
                  {{- range $hostname := $root.Values.targetNodes }}
                  - {{ $hostname }}
                  {{- end }}
        {{ end }}

        tolerations:
        - key: nvidia.com/gpu
          operator: Exists
        - key: cloud.google.com/impending-node-termination
          operator: Exists
        volumes:
        - name: nvidia-dir-host
          hostPath:
            path: /home/kubernetes/bin/nvidia
        {{- if not $root.Values.gpuPlatformSettings.useHostPlugin }}
        - name: nccl-plugin-volume
          emptyDir: {}
        {{- end }}
        - name: sys
          hostPath:
            path: /sys
        - name: proc-sys
          hostPath:
           path: /proc/sys
        - name: aperture-devices
          hostPath:
            path: /dev/aperture_devices
        - name: workload-terminated-volume
          emptyDir: {}
        - name: local-ssd
          hostPath:
            path: /mnt/stateful_partition/kube-ephemeral-ssd
        - name: shared-memory
          emptyDir:
            medium: "Memory"
            sizeLimit: 250Gi

        {{- range $gcs := $root.Values.volumes.gcsMounts }}
        - name: "{{ $gcs.bucketName }}"
          csi:
            driver: gcsfuse.csi.storage.gke.io
            volumeAttributes:
              bucketName: "{{ $gcs.bucketName }}"
        {{- end}}

        initContainers:
        {{- if not $root.Values.gpuPlatformSettings.useHostPlugin }}
        - name: nccl-plugin-installer
          image: "{{ $root.Values.gpuPlatformSettings.ncclPluginImage }}"
          imagePullPolicy: Always
          volumeMounts:
            - name: nccl-plugin-volume
              mountPath: /usr/local/nccl-plugin
          env:
          - name: BUILD_TYPE
            value: "{{ $root.Values.gpuPlatformSettings.ncclBuildType }}"
          command:
          - bash
          - -c
          - |
            set -ex
            chmod 755 /scripts/container_entry.sh
            /scripts/container_entry.sh install --install-nccl --nccl-buildtype ${BUILD_TYPE}
            cp -r /var/lib/tcpxo/* /usr/local/nccl-plugin/

        {{- end }}

        - name: tcpxo-daemon
          image: {{ $root.Values.gpuPlatformSettings.rxdmImage }}
          imagePullPolicy: Always
          securityContext:
            capabilities:
              add:
                - NET_ADMIN
                - NET_BIND_SERVICE
          restartPolicy: Always
          volumeMounts:
          - name: nvidia-dir-host
            mountPath: /usr/local/nvidia
          - name: sys
            mountPath: /hostsysfs
          - name: proc-sys
            mountPath: /hostprocsysfs
          env:
          - name: LD_LIBRARY_PATH
            value: /usr/local/nvidia/lib64
          command:
          - bash
          - -c
          - |
            cleanup() {
              echo "Received SIGTERM, exiting RxDM"
              if [ -n "$child_pid" ]; then
                echo "Sending SIGTERM to child process"
                kill -TERM "$child_pid"
              fi
              exit 0
            }
            trap cleanup SIGTERM

            chmod 755 /fts/entrypoint_rxdm_container.sh
            /fts/entrypoint_rxdm_container.sh --num_hops=2 --num_nics=8  --uid= --alsologtostderr & child_pid=$!

            wait "$child_pid"

        containers:
          - name: sglang-leader
            image: {{ .Values.job.image.repository }}:{{ .Values.job.image.tag }}
            securityContext:
              privileged: true
              capabilities:
                add:
                  - SYS_ADMIN
            resources:
              requests:
                nvidia.com/gpu: {{ $gpusPerNode }}
              limits:
                nvidia.com/gpu: {{ $gpusPerNode }}
            env:
              - name: JOB_ORCHESTRATOR
                value: "gke"
              - name: HF_TOKEN
                valueFrom:
                  secretKeyRef:
                    name: "{{ .Values.huggingface.secretName }}"
                    key: "{{ .Values.huggingface.secretData.token }}"
              - name: LWS_WORKER_INDEX
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.labels['leaderworkerset.sigs.k8s.io/worker-index']
              - name: HF_HUB_ENABLE_HF_TRANSFER
                value: "1"
              - name: TORCH_DISTRIBUTED_DEBUG
                value: "INFO"
              {{- if  $root.Values.gpuPlatformSettings.useHostPlugin }}
              - name: LD_LIBRARY_PATH
                value: /usr/local/nvidia/lib64
              - name: NCCL_LIB_DIR
                value: /usr/local/nvidia/lib64
              {{- else }}
              - name: LD_LIBRARY_PATH
                value: /usr/local/nccl-plugin/lib64:/usr/local/nvidia/lib64
              - name: NCCL_LIB_DIR
                value: /usr/local/nccl-plugin/lib64
              {{- end }}
              - name: NCCL_FASTRAK_LLCM_DEVICE_DIRECTORY
                value: /dev/aperture_devices

              # NCCL settings from A3Mega configuration
              - name: NCCL_FASTRAK_CTRL_DEV
                value: "eth0"
              - name: NCCL_SOCKET_IFNAME
                value: "eth0"
              - name: NCCL_CROSS_NIC
                value: "0"
              - name: NCCL_ALGO
                value: "Ring,Tree"
              - name: NCCL_PROTO
                value: "Simple"
              - name: NCCL_MIN_NCHANNELS
                value: "4"
              - name: NCCL_DYNAMIC_CHUNK_SIZE
                value: "524288"
              - name: NCCL_P2P_NET_CHUNKSIZE
                value: "524288"
              - name: NCCL_P2P_PCI_CHUNKSIZE
                value: "524288"
              - name: NCCL_P2P_NVL_CHUNKSIZE
                value: "1048576"
              - name: NCCL_FASTRAK_NUM_FLOWS
                value: "2"
              - name: NCCL_BUFFSIZE
                value: "8388608"
              - name: NCCL_NET_GDR_LEVEL
                value: "PIX"
              - name: NCCL_DEBUG_SUBSYS
                value: "INIT,GRAPH,ENV,TUNING,NET"
              - name: NCCL_FASTRAK_ENABLE_HOTPATH_LOGGING
                value: "0"
              - name: NCCL_FASTRAK_USE_SNAP
                value: "1"
              - name: NCCL_FASTRAK_ENABLE_CONTROL_CHANNEL
                value: "0"
              - name: NCCL_FASTRAK_USE_LLCM
                value: "1"
              - name: NCCL_TUNER_PLUGIN
                value: "libnccl-tuner.so"
              - name: NCCL_TUNER_CONFIG_PATH
                value: "/usr/local/nccl-plugin/lib64/a3plus_tuner_config.textproto"
              - name: NCCL_SHIMNET_GUEST_CONFIG_CHECKER_CONFIG_FILE
                value: "/usr/local/nccl-plugin/lib64/a3plus_guest_config.textproto"
              - name: NCCL_NVLS_ENABLE
                value: "0"
              - name: NCCL_FASTRAK_PLUGIN_ACCEPT_TIMEOUT_MS
                value: "600000"
              - name: CUDA_VISIBLE_DEVICES
                value: "0,1,2,3,4,5,6,7"
              - name: NCCL_FASTRAK_IFNAME
                value: "eth1,eth2,eth3,eth4,eth5,eth6,eth7,eth8"

              # The following is needed to prevent send-receive stalling execution
              - name: NVTE_FWD_LAYERNORM_SM_MARGIN
                value: "8"
              - name: NVTE_BWD_LAYERNORM_SM_MARGIN
                value: "8"

              # NCCL settings
              - name: NCCL_P2P_PXN_LEVEL
                value: "0"

              {{- range $environment_variable := $root.Values.network.ncclSettings }}
              - name: {{ $environment_variable.name }}
                value: "{{ $environment_variable.value }}"
              {{- end }}

            command:
            - bash
            - -c
            - |
              # Launch the server
              echo "Pod on $(hostname --fqdn) is running"

              GLOO_SOCKET_IFNAME=eth0 python3 -m sglang.launch_server \
                --model-path {{ $root.Values.model.name }} \
                --tp {{ $root.Values.model.tp_size }} \
                --dist-init-addr ${LWS_LEADER_ADDRESS}:6002 \
                --nnodes ${LWS_GROUP_SIZE} \
                --node-rank ${LWS_WORKER_INDEX} \
                --trust-remote-code{{- if $root.Values.sglang.serverArgs }} \ {{- end }}
              {{- if $root.Values.sglang.serverArgs }}
                {{- $first := true }}
                {{- range $key, $value := $root.Values.sglang.serverArgs }}
                  {{- if not $first }} \ {{- end }}
                  {{- $first = false }}
                {{- if kindIs "bool" $value }}
                --{{ $key }}{{ if not $value }} false{{ end }}
                {{- else }}
                --{{ $key }} {{ $value }}
                {{- end }}
                {{- end }}
              {{- end }}

            ports:
              - containerPort: {{ $root.Values.sglang.service.ports.http }}
            readinessProbe:
              tcpSocket:
                port: {{ $root.Values.sglang.service.ports.http }}
              initialDelaySeconds: 15
              periodSeconds: 10

            volumeMounts:
            - name: nvidia-dir-host
              mountPath: /usr/local/nvidia
            - name: aperture-devices
              mountPath: /dev/aperture_devices
            {{- if not $root.Values.gpuPlatformSettings.useHostPlugin }}
            - name: nccl-plugin-volume
              mountPath: /usr/local/nccl-plugin
            {{- end }}
            - name: sys
              mountPath: /hostsysfs
            - name: proc-sys
              mountPath: /hostprocsysfs
            - name: workload-terminated-volume
              mountPath: /semaphore
            - name: shared-memory
              mountPath: /dev/shm
            - name: local-ssd
              mountPath: "{{ $root.Values.volumes.ssdMountPath }}"

            {{- range $gcs := $root.Values.volumes.gcsMounts }}
            - name: "{{ $gcs.bucketName }}"
              mountPath: "{{ $gcs.mountPath }}"
            {{- end }}

    workerTemplate:
      metadata:
        labels:
          role: worker
          app: {{ .Release.Name }}
        annotations:
          gke-gcsfuse/volumes: "true"
          gke-gcsfuse/cpu-limit: "0"
          gke-gcsfuse/memory-limit: "0"
          gke-gcsfuse/ephemeral-storage-limit: "0"
          devices.gke.io/container.tcpxo-daemon: |+
            - path: /dev/nvidia0
            - path: /dev/nvidia1
            - path: /dev/nvidia2
            - path: /dev/nvidia3
            - path: /dev/nvidia4
            - path: /dev/nvidia5
            - path: /dev/nvidia6
            - path: /dev/nvidia7
            - path: /dev/nvidiactl
            - path: /dev/nvidia-uvm
            - path: /dev/dmabuf_import_helper
          networking.gke.io/default-interface: "eth0"
          networking.gke.io/interfaces: |
          {{- if $root.Values.network.subnetworks }}
            [
              {{- range $i, $subnetwork := $root.Values.network.subnetworks }}
              {"interfaceName":"eth{{ $i }}","network":"{{ $subnetwork }}"}{{ eq $i 8 | ternary "" ","}}
              {{- end }}
            ]
          {{- else }}
            [
              {"interfaceName":"eth0","network":"default"},
              {{- range  $i := until 8 }}
              {"interfaceName":"eth{{ add 1 $i }}","network":"{{ $root.Values.clusterName }}-gpunet-{{ $i }}-subnet"}{{ eq $i 7 | ternary "" ","}}
              {{- end }}
            ]
          {{- end}}
      spec:
        subdomain: "{{.Release.Name}}"
        restartPolicy: Always
        {{ if $root.Values.targetNodes }}
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: kubernetes.io/hostname
                  operator: In
                  values:
                  {{- range $hostname := $root.Values.targetNodes }}
                  - {{ $hostname }}
                  {{- end }}
        {{ end }}

        tolerations:
        - key: nvidia.com/gpu
          operator: Exists
        - key: cloud.google.com/impending-node-termination
          operator: Exists

        volumes:
        - name: nvidia-dir-host
          hostPath:
            path: /home/kubernetes/bin/nvidia
        {{- if not $root.Values.gpuPlatformSettings.useHostPlugin }}
        - name: nccl-plugin-volume
          emptyDir: {}
        {{- end }}
        - name: sys
          hostPath:
            path: /sys
        - name: proc-sys
          hostPath:
           path: /proc/sys
        - name: aperture-devices
          hostPath:
            path: /dev/aperture_devices
        - name: workload-terminated-volume
          emptyDir: {}
        - name: local-ssd
          hostPath:
            path: /mnt/stateful_partition/kube-ephemeral-ssd
        - name: shared-memory
          emptyDir:
            medium: "Memory"
            sizeLimit: 250Gi


        {{- range $gcs := $root.Values.volumes.gcsMounts }}
        - name: "{{ $gcs.bucketName }}"
          csi:
            driver: gcsfuse.csi.storage.gke.io
            volumeAttributes:
              bucketName: "{{ $gcs.bucketName }}"
        {{- end}}

        initContainers:
        {{- if not $root.Values.gpuPlatformSettings.useHostPlugin }}
        - name: nccl-plugin-installer
          image: "{{ $root.Values.gpuPlatformSettings.ncclPluginImage }}"
          imagePullPolicy: Always
          volumeMounts:
            - name: nccl-plugin-volume
              mountPath: /usr/local/nccl-plugin
          env:
          - name: BUILD_TYPE
            value: "{{ $root.Values.gpuPlatformSettings.ncclBuildType }}"
          command:
          - bash
          - -c
          - |
            set -ex
            chmod 755 /scripts/container_entry.sh
            /scripts/container_entry.sh install --install-nccl --nccl-buildtype ${BUILD_TYPE}
            cp -r /var/lib/tcpxo/* /usr/local/nccl-plugin/

        {{- end }}


        - name: tcpxo-daemon
          image: {{ $root.Values.gpuPlatformSettings.rxdmImage }}
          imagePullPolicy: Always
          securityContext:
            capabilities:
              add:
                - NET_ADMIN
                - NET_BIND_SERVICE
          restartPolicy: Always
          volumeMounts:
          - name: nvidia-dir-host
            mountPath: /usr/local/nvidia
          - name: sys
            mountPath: /hostsysfs
          - name: proc-sys
            mountPath: /hostprocsysfs
          env:
          - name: LD_LIBRARY_PATH
            value: /usr/local/nvidia/lib64
          command:
          - bash
          - -c
          - |
            cleanup() {
              echo "Received SIGTERM, exiting RxDM"
              if [ -n "$child_pid" ]; then
                echo "Sending SIGTERM to child process"
                kill -TERM "$child_pid"
              fi
              exit 0
            }
            trap cleanup SIGTERM

            chmod 755 /fts/entrypoint_rxdm_container.sh
            /fts/entrypoint_rxdm_container.sh --num_hops=2 --num_nics=8  --uid= --alsologtostderr & child_pid=$!

            wait "$child_pid"

        containers:
          - name: sglang-worker
            image: {{ .Values.job.image.repository }}:{{ .Values.job.image.tag }}
            securityContext:
              privileged: true
              capabilities:
                add:
                  - SYS_ADMIN
            resources:
              requests:
                nvidia.com/gpu: {{ $gpusPerNode }}
              limits:
                nvidia.com/gpu: {{ $gpusPerNode }}
            env:
              - name: JOB_ORCHESTRATOR
                value: "gke"
              - name: HF_TOKEN
                valueFrom:
                  secretKeyRef:
                    name: "{{ .Values.huggingface.secretName }}"
                    key: "{{ .Values.huggingface.secretData.token }}"
              - name: LWS_WORKER_INDEX
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.labels['leaderworkerset.sigs.k8s.io/worker-index']
              - name: HF_HUB_ENABLE_HF_TRANSFER
                value: "1"
              - name: TORCH_DISTRIBUTED_DEBUG
                value: "INFO"
              {{- if  $root.Values.gpuPlatformSettings.useHostPlugin }}
              - name: LD_LIBRARY_PATH
                value: /usr/local/nvidia/lib64
              - name: NCCL_LIB_DIR
                value: /usr/local/nvidia/lib64
              {{- else }}
              - name: LD_LIBRARY_PATH
                value: /usr/local/nccl-plugin/lib64:/usr/local/nvidia/lib64
              - name: NCCL_LIB_DIR
                value: /usr/local/nccl-plugin/lib64
              {{- end }}
              - name: NCCL_FASTRAK_LLCM_DEVICE_DIRECTORY
                value: /dev/aperture_devices

              # NCCL settings from A3Mega configuration
              - name: NCCL_FASTRAK_CTRL_DEV
                value: "eth0"
              - name: NCCL_SOCKET_IFNAME
                value: "eth0"
              - name: NCCL_CROSS_NIC
                value: "0"
              - name: NCCL_ALGO
                value: "Ring,Tree"
              - name: NCCL_PROTO
                value: "Simple"
              - name: NCCL_MIN_NCHANNELS
                value: "4"
              - name: NCCL_DYNAMIC_CHUNK_SIZE
                value: "524288"
              - name: NCCL_P2P_NET_CHUNKSIZE
                value: "524288"
              - name: NCCL_P2P_PCI_CHUNKSIZE
                value: "524288"
              - name: NCCL_P2P_NVL_CHUNKSIZE
                value: "1048576"
              - name: NCCL_FASTRAK_NUM_FLOWS
                value: "2"
              - name: NCCL_BUFFSIZE
                value: "8388608"
              - name: NCCL_NET_GDR_LEVEL
                value: "PIX"
              - name: NCCL_DEBUG_SUBSYS
                value: "INIT,GRAPH,ENV,TUNING,NET"
              - name: NCCL_FASTRAK_ENABLE_HOTPATH_LOGGING
                value: "0"
              - name: NCCL_FASTRAK_USE_SNAP
                value: "1"
              - name: NCCL_FASTRAK_ENABLE_CONTROL_CHANNEL
                value: "0"
              - name: NCCL_FASTRAK_USE_LLCM
                value: "1"
              - name: NCCL_TUNER_PLUGIN
                value: "libnccl-tuner.so"
              - name: NCCL_TUNER_CONFIG_PATH
                value: "/usr/local/nccl-plugin/lib64/a3plus_tuner_config.textproto"
              - name: NCCL_SHIMNET_GUEST_CONFIG_CHECKER_CONFIG_FILE
                value: "/usr/local/nccl-plugin/lib64/a3plus_guest_config.textproto"
              - name: NCCL_NVLS_ENABLE
                value: "0"
              - name: NCCL_FASTRAK_PLUGIN_ACCEPT_TIMEOUT_MS
                value: "600000"
              - name: CUDA_VISIBLE_DEVICES
                value: "0,1,2,3,4,5,6,7"
              - name: NCCL_FASTRAK_IFNAME
                value: "eth1,eth2,eth3,eth4,eth5,eth6,eth7,eth8"

              # The following is needed to prevent send-receive stalling execution
              - name: NVTE_FWD_LAYERNORM_SM_MARGIN
                value: "8"
              - name: NVTE_BWD_LAYERNORM_SM_MARGIN
                value: "8"

              # NCCL settings
              - name: NCCL_P2P_PXN_LEVEL
                value: "0"

              {{- range $environment_variable := $root.Values.network.ncclSettings }}
              - name: {{ $environment_variable.name }}
                value: "{{ $environment_variable.value }}"
              {{- end }}

            command:
            - bash
            - -c
            - |
              # Launch the server
              echo "Pod on $(hostname --fqdn) is running"
              GLOO_SOCKET_IFNAME=eth0 python3 -m sglang.launch_server \
                --model-path {{ .Values.model.name }} \
                --tp {{ .Values.model.tp_size }} \
                --dist-init-addr ${LWS_LEADER_ADDRESS}:6002 \
                --nnodes ${LWS_GROUP_SIZE} \
                --node-rank ${LWS_WORKER_INDEX} \
                --trust-remote-code{{- if .Values.sglang.serverArgs }} \ {{- end }}
              {{- if .Values.sglang.serverArgs }}
                {{- $first := true }}
                {{- range $key, $value := .Values.sglang.serverArgs }}
                  {{- if not $first }} \ {{- end }}
                  {{- $first = false }}
                {{- if kindIs "bool" $value }}
                --{{ $key }}{{ if not $value }} false{{ end }}
                {{- else }}
                --{{ $key }} {{ $value }}
                {{- end }}
                {{- end }}
              {{- end }}

            volumeMounts:
            - name: nvidia-dir-host
              mountPath: /usr/local/nvidia
            - name: aperture-devices
              mountPath: /dev/aperture_devices
            {{- if not $root.Values.gpuPlatformSettings.useHostPlugin }}
            - name: nccl-plugin-volume
              mountPath: /usr/local/nccl-plugin
            {{- end }}
            - name: sys
              mountPath: /hostsysfs
            - name: proc-sys
              mountPath: /hostprocsysfs
            - name: workload-terminated-volume
              mountPath: /semaphore
            - name: shared-memory
              mountPath: /dev/shm
            - name: local-ssd
              mountPath: "{{ $root.Values.volumes.ssdMountPath }}"

            {{- range $gcs := $root.Values.volumes.gcsMounts }}
            - name: "{{ $gcs.bucketName }}"
              mountPath: "{{ $gcs.mountPath }}"
            {{- end }}

