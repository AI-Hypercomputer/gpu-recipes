# Copyright 2024 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

{{ $timestamp := now | date "2006-01-02-15-04" }} #unixEpoch
{{ $jobSuffix := randAlphaNum 4 | lower }}
{{ $jobuuid := uuidv4 }}

{{ $nodes := div .Values.workload.gpus 8 | max 1 }}
{{ $gpusPerNode := min .Values.workload.gpus 8 }}

{{- $root := . -}}
apiVersion: batch/v1
kind: Job
metadata:
  name: "{{ .Release.Name }}"
  namespace: default
  labels:
  {{- if $root.Values.queue }}
    kueue.x-k8s.io/queue-name: "{{ $root.Values.queue }}"
  {{- end }}
spec:
  {{- if $root.Values.queue }}
  suspend: true
  {{- end }}
  parallelism: {{ $nodes }}
  completions: {{ $nodes }}
  backoffLimit: 0
  completionMode: Indexed
  ttlSecondsAfterFinished: 43200
  template:
   metadata:
    annotations:
      kubectl.kubernetes.io/default-container: workload
      {{- if $root.Values.volumes.gcsMounts }}
      gke-gcsfuse/volumes: "true"
      gke-gcsfuse/cpu-limit: "0"
      gke-gcsfuse/memory-limit: "0"
      gke-gcsfuse/ephemeral-storage-limit: "0"
      {{- end}}

   spec:
    schedulingGates:
    - name: "gke.io/topology-aware-auto-scheduling"
    hostNetwork: true
    dnsPolicy: ClusterFirstWithHostNet
    subdomain: "{{.Release.Name}}"
    restartPolicy: Never
    # Testing for local ssd
    nodeSelector:
        cloud.google.com/gke-ephemeral-storage-local-ssd: "true"

    {{ if $root.Values.targetNodes }}
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
              {{- range $hostname := $root.Values.targetNodes }}
              - {{ $hostname }}
              {{- end }}
    {{ end }}

    tolerations:
    - operator: "Exists"
      key: nvidia.com/gpu
    - operator: "Exists"
      key: cloud.google.com/impending-node-termination

    volumes:
    - name: nvidia # plugin installed by daemonset
      hostPath:
        path: /home/kubernetes/bin/nvidia/
    {{ if ne $root.Values.network.stack "tcp" }}
    - name: tcpx-daemon-socket
      hostPath:
        path: /run/tcpx
    {{ end }}
    - name: workload-configuration
      configMap:
        name: "{{.Release.Name}}"
    - name: workload-terminated-volume
      emptyDir: {}
    - name: local-ssd
      hostPath:
        path: /mnt/stateful_partition/kube-ephemeral-ssd
    - name: shared-memory
      emptyDir:
        medium: "Memory"
        sizeLimit: 250Gi

    {{- range $gcs := $root.Values.volumes.gcsMounts }}
    - name: "{{ $gcs.bucketName }}"
      csi:
        driver: gcsfuse.csi.storage.gke.io
        volumeAttributes:
          bucketName: "{{ $gcs.bucketName }}"
          mountOptions: "max-conns-per-host=0,metadata-cache:ttl-secs:-1,metadata-cache:stat-cache-max-size-mb:-1,metadata-cache:type-cache-max-size-mb:-1,file-system:kernel-list-cache-ttl-secs:-1"
    {{- end}}

    initContainers:
    {{ if $root.Values.gcsDownload }}
    - name: training-data-downloader
      image: gcr.io/google.com/cloudsdktool/google-cloud-cli
      volumeMounts:
      - name: local-ssd
        mountPath: "{{ $root.Values.volumes.ssdMountPath }}"

      {{- range $gcs := $root.Values.volumes.gcsMounts }}
      - name: "{{ $gcs.bucketName }}"
        mountPath: "{{ $gcs.mountPath }}"
      {{- end }}

      env:
      - name: GCS_DATA_SOURCE
        value: "{{ $root.Values.gcsDownload.source }}"
      - name: GCS_DATA_TARGET
        value: "{{ $root.Values.gcsDownload.target }}"
      command:
        - /bin/sh
        - -c
        - |
          echo "Caching training data from $GCS_DATA_SOURCE to $GCS_DATA_TARGET"
          mkdir -p $GCS_DATA_TARGET

          SECONDS=0
          gcloud storage rsync \
            --recursive \
            $GCS_DATA_SOURCE $GCS_DATA_TARGET
          duration=$SECONDS
          echo "Transferred or synchronized $GCS_DATA_SOURCE to $GCS_DATA_TARGET in $duration seconds."
    {{ end }}

    containers:

    # Either the tcpx or tcpxo receive daemon
    {{ if ne $root.Values.network.stack "tcp" }}
    - name: network-rx-daemon
      image: "{{ $root.Values.network.daemonVersion }}"
      imagePullPolicy: Always
      securityContext:
        privileged: true
      volumeMounts:
      - name: tcpx-daemon-socket
        mountPath: /tmp
      - name: workload-terminated-volume
        mountPath: /semaphore
      - name: nvidia
        mountPath: "/usr/local/nvidia"
      env:
      - name: LD_LIBRARY_PATH
        value: /usr/local/nvidia/lib64

      {{ if eq $root.Values.network.stack "tcpx" }}
      command:
      - bash
      - -c
      - |
        /tcpgpudmarxd/build/app/tcpgpudmarxd --gpu_nic_preset a3vm --gpu_shmem_type fd --setup_param "--verbose 128 2 0" &
        while [ ! -e "/semaphore/workload_terminated" ]; do sleep 10; done
        pkill -e "^"tcpgpudmarxd || true
        sleep 15
      {{ end }}

      {{ if eq $root.Values.network.stack "tcpxo" }}
      command:
      - bash
      - -c
      - |
        /fts/entrypoint_rxdm_container.sh --num_hops 2 --num_nics 8 --uid=  --alsologtostderr &
        while [ ! -e "/semaphore/workload_terminated" ]; do sleep 10; done
        pkill -e "^"entrypoint_rxdm_container.sh || true
        sleep 15
      {{ end }}

    {{ end }}

    # Workload Container
    - name: workload
      image: "{{ $root.Values.workload.image }}"
      imagePullPolicy: Always
      securityContext:
        privileged: true
      env:
      - name: JOB_IDENTIFIER
        value: "{{ .Release.Name }}-{{ $root.Values.sessionid }}"
      - name: JOB_TIMESTAMP
        value: "{{ $timestamp }}"
      - name: JOB_UUID
        value: "{{ $jobuuid }}"
      - name: JOB_ORCHESTRATOR
        value: "gke"
      - name: SSD_MOUNT_PATH
        value: "{{ $root.Values.volumes.ssdMountPath }}"
      {{- with (first .Values.volumes.gcsMounts) }}
      - name: GCS_BUCKET
        value: {{ .bucketName }}
      {{- end }}

      # JAX-specific environment variables
      - name: JAX_COORDINATOR_ADDRESS
        value: "{{.Release.Name}}-0.{{.Release.Name}}.default.svc.cluster.local"
      - name: JAX_COORDINATOR_PORT
        value: "6002"
      - name: TF_CPP_VMODULE
        value: "profile_guided_latency_estimator=10"
      - name: TF_CPP_MIN_LOG_LEVEL
        value: "0"
      - name: TF_CPP_MAX_LOG_LEVEL
        value: "100"
      - name: XLA_PYTHON_CLIENT_MEM_FRACTION
        value: "0.9"
      - name: CUDA_DEVICE_MAX_CONNECTIONS
        value: "1"
      - name: NVTE_FUSED_ATTN
        value: "1"
      - name: JAX_REMOVE_CUSTOM_PARTITIONING_PTR_FROM_CACHE_KEY
        value: "true"
      - name: JAX_ENABLE_PGLE
        value: "false"

      # Job Configuration
      - name: NNODES
        value: "{{ $nodes }}"
      - name: GPUS_PER_NODE
        value: "{{ $gpusPerNode }}"
      - name: GLOO_SOCKET_IFNAME
        value: "eth0"
      - name: LD_LIBRARY_PATH
        value: /usr/local/nvidia/lib64

      # The following is needed to prevent send-receive stalling execution
      - name: NVTE_FWD_LAYERNORM_SM_MARGIN
        value: "8"
      - name: NVTE_BWD_LAYERNORM_SM_MARGIN
        value: "8"

      {{ if ne $root.Values.network.stack "tcp" }}

      # The following TCPxo settings should likely not be adjusted:
      {{ if eq $root.Values.network.stack "tcpxo" }}
      - name: NCCL_BUFFSIZE
        value: "8388608"
      - name: NCCL_FASTRAK_CTRL_DEV
        value: "eth0"
      - name: NCCL_FASTRAK_IFNAME
        value: "eth1,eth2,eth3,eth4,eth5,eth6,eth7,eth8"
      - name: NCCL_FASTRAK_NUM_FLOWS
        value: "2"
      - name: NCCL_FASTRAK_NUM_FLOWS_PER_GROUP
        value: "1"
      - name: NCCL_FASTRAK_ENABLE_CONTROL_CHANNEL
        value: "0"
      - name: NCCL_FASTRAK_ENABLE_HOTPATH_LOGGING
        value: "0"
      - name: NCCL_FASTRAK_USE_SNAP
        value: "1"
      - name: NCCL_FASTRAK_USE_LLCM
        value: "1"

      # The following NCCL tuner settings should likely not be adjusted:
      - name: NCCL_TUNER_PLUGIN
        value: "libnccl-tuner.so"
      - name: NCCL_TUNER_CONFIG_PATH
        value: "/usr/local/nvidia/lib64/a3plus_tuner_config.textproto"
      - name: NCCL_SHIMNET_GUEST_CONFIG_CHECKER_CONFIG_FILE
        value: "/usr/local/nvidia/lib64/a3plus_guest_config.textproto"

      {{ end }}

      {{ if eq $root.Values.network.stack "tcpx" }}
      - name: NCCL_GPUDIRECTTCPX_CTRL_DEV
        value: "eth0"
      - name: NCCL_GPUDIRECTTCPX_SOCKET_IFNAME
        value: "eth1,eth2,eth3,eth4,eth5,eth6,eth7,eth8"
      - name: NCCL_GPUDIRECTTCPX_TX_BINDINGS
        value: "eth1:8-21,112-125;eth2:8-21,112-125;eth3:60-73,164-177;eth4:60-73,164-177"
      - name: NCCL_GPUDIRECTTCPX_RX_BINDINGS
        value: "eth1:22-35,126-139;eth2:22-35,126-139;eth3:74-87,178-191;eth4:74-87,178-191"
      - name: NCCL_GPUDIRECTTCPX_PROGRAM_FLOW_STEERING_WAIT_MICROS
        value: "500000"
      {{ end }}

       # The following NCCL settings should likely not be adjusted:
      - name: NCCL_SOCKET_IFNAME
        value: "eth0"
      - name: NCCL_DYNAMIC_CHUNK_SIZE
        value: "524288"
      - name: NCCL_P2P_NET_CHUNKSIZE
        value: "524288"
      - name: NCCL_P2P_PCI_CHUNKSIZE
        value: "524288"
      - name: NCCL_P2P_NVL_CHUNKSIZE
        value: "1048576"
      - name: NCCL_CROSS_NIC
        value: "0"
      - name: NCCL_PROTO
        value: "Simple"
      - name: NCCL_NET_GDR_LEVEL
        value: "PIX"
      - name: NCCL_P2P_PXN_LEVEL
        value: "0"
      - name: NCCL_NVLS_ENABLE
        value: "0"
      - name: TORCH_NCCL_HEARTBEAT_TIMEOUT_SEC
        value: "1800"
      - name: NCCL_ALGO
        value: "Ring,Tree"
      - name: NCCL_MIN_NCHANNELS
        value: "4"

      {{- range $environment_variable := $root.Values.network.ncclSettings }}
      - name: {{ $environment_variable.name }}
        value: "{{ $environment_variable.value }}"
      {{- end }}

      # XLA Flags
      - name: XLA_FLAGS
        valueFrom:
          configMapKeyRef:
            name: "{{ .Release.Name }}"
            key: xla-flags

      {{ end }}

      command:
      - bash
      - -c
      - |
        function on_script_completion {
          # Note: This semaphore is used to terminate the TCPx side-car
          touch /semaphore/workload_terminated
        }
        trap on_script_completion EXIT
        echo "Pod on $(hostname --fqdn) is running"
        echo "Pod is assigned job index of $JOB_COMPLETION_INDEX"
        echo "Job ID is $JOB_IDENTIFIER"

        echo "Running nvidia-smi"
        nvidia-smi

        echo "Warning: Set LD_LIBRARY_PATH=$LD_LIBRARY_PATH to override the NCCL library"
        export LD_LIBRARY_PATH=/usr/local/cuda-12.6/compat:/usr/local/nvidia/lib64
        ldconfig $LD_LIBRARY_PATH

        echo "Added ${LD_LIBRARY_PATH} to ldconfig:"
        ldconfig -p | grep libcuda | sed 's/^/  /'

        echo "Contents of ${LD_LIBRARY_PATH}:"
        ls ${LD_LIBRARY_PATH} | sed 's/^/  /'


        touch $SSD_MOUNT_PATH/hello-from-$HOSTNAME.txt
        echo "Local SSD contents (path $SSD_MOUNT_PATH):"; ls $SSD_MOUNT_PATH | sed 's/^/  /'


        echo "MaxText configuration file:"
        cat /etc/workload-configuration/maxtext-configuration.yaml | sed 's/^/| /'
        echo ""

        echo "Detected the following additional workload arguments:"
        {{- range $root.Values.workload.arguments }}
        echo "{{ . }}"
        {{- end }}

        sleep 10 # <- Hack to allow some time for service to boot

        mount /tmp -o remount,exec
        chmod -R a+rwx /tmp

        export NODE_RANK=$JOB_COMPLETION_INDEX
        echo "Launching MaxText as node rank $NODE_RANK out of $NNODES nodes"

        if [ "$NODE_RANK" -eq "1" ]; then
          echo "Launching nvidia-smi in daemon mode with (20 sec delay)"
          nvidia-smi dmon -d 20 -s pum &
        fi

        echo "XLA Flags: $XLA_FLAGS"

        export JAX_COORDINATOR_IP=$(nslookup "$JAX_COORDINATOR_ADDRESS" 2>/dev/null | awk '/^Address: / { print $2 }' | head -n 1)

        # Parsing Configuration
        while IFS= read -r line || [[ -n "$line" ]]; \
        do [[ -z "$line" ]] && continue; \
        [[ "$line" == \#* ]] && continue; \
        key=$(echo "$line" | cut -d':' -f1 | tr -d '[:space:]'); \
        value=$(echo "$line" | cut -d':' -f2 | tr -d '[:space:]'); \
        export OPTIONS+=("$key=$value"); \
        done < /etc/workload-configuration/maxtext-configuration.yaml;
        echo "===== MaxText Configuration ====="
        echo ${OPTIONS[@]}
        echo "================================="
        echo "GCS_BUCKET: ${GCS_BUCKET}" 

        python MaxText/train.py MaxText/configs/base.yml "${OPTIONS[@]}" \
        base_output_directory=gs://${GCS_BUCKET}/maxtext \
        run_name=${JOB_IDENTIFIER} \
        steps={{ $root.Values.workload.steps }}

        echo "Pod on $(hostname --fqdn) is exiting"

      volumeMounts:
        - name: nvidia
          mountPath: /usr/local/nvidia
        {{ if ne $root.Values.network.stack "tcp" }}
        - name: tcpx-daemon-socket
          mountPath: /tmp
        {{ end }}
        - name: workload-terminated-volume
          mountPath: /semaphore
        - name: workload-configuration
          mountPath: /etc/workload-configuration
        - name: shared-memory
          mountPath: /dev/shm
        - name: local-ssd
          mountPath: "{{ $root.Values.volumes.ssdMountPath }}"

        {{- range $gcs := $root.Values.volumes.gcsMounts }}
        - name: "{{ $gcs.bucketName }}"
          mountPath: "{{ $gcs.mountPath }}"
        {{- end }}
      resources:
        limits:
          nvidia.com/gpu: {{ $gpusPerNode }}
