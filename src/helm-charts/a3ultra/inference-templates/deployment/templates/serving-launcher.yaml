# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

{{ $nodes := div .Values.workload.gpus 8 | max 1 }}
{{ $gpusPerNode := min .Values.workload.gpus 8 }}

{{ $root := . }}

apiVersion: apps/v1
kind: Deployment
metadata:
  name: "{{ .Release.Name }}"
  namespace: default
  labels:
    app: {{ .Release.Name }}-serving
    {{- if $root.Values.queue }}
    kueue.x-k8s.io/queue-name: "{{ $root.Values.queue }}"
    {{- end }}
spec:
  replicas: {{ $nodes }}
  selector:
    matchLabels:
      app: {{ .Release.Name }}-serving
  template:
    metadata:
      labels:
        app: {{ .Release.Name }}-serving
      annotations:
        kubectl.kubernetes.io/default-container: serving
        {{- if $root.Values.volumes.gcsVolumes }}
        gke-gcsfuse/volumes: "true"
        gke-gcsfuse/cpu-limit: "0"
        gke-gcsfuse/memory-limit: "0"
        gke-gcsfuse/ephemeral-storage-limit: "0"
        {{- end }}
        {{- if and $root.Values.queue $root.Values.dwsSettings.maxRunDurationSeconds }}
        provreq.kueue.x-k8s.io/maxRunDurationSeconds: "{{ $root.Values.dwsSettings.maxRunDurationSeconds }}"
        {{- end }}
        {{- if not $root.Values.network.hostNetwork }}
        networking.gke.io/default-interface: "eth0"
        networking.gke.io/interfaces: |
        {{- if $root.Values.network.subnetworks }}
          [
            {{- range $i, $subnetwork := $root.Values.network.subnetworks }}
            {"interfaceName":"eth{{ $i }}","network":"{{ $subnetwork }}"}{{ eq $i 9 | ternary "" ","}}
            {{- end }}
          ]
        {{- else }}
          [
            {"interfaceName":"eth0","network":"default"},
            {"interfaceName":"eth1","network":"gvnic-1"},
            {{- range  $i := until 8 }}
            {"interfaceName":"eth{{ add 2 $i }}","network":"rdma-{{ $i }}"}{{ eq $i 7 | ternary "" ","}}
            {{- end }}
          ]
        {{- end }}
        {{- end }}
    spec:
      {{- if $root.Values.network.hostNetwork }}
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      {{- end }}
      subdomain: "{{.Release.Name}}"
      restartPolicy: Always
      {{- if $root.Values.targetNodes }}
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/hostname
                operator: In
                values:
                {{ range $hostname := $root.Values.targetNodes }}
                - {{ $hostname }}
                {{ end }}
      {{- end }}
      tolerations:
      - operator: "Exists"
        key: nvidia.com/gpu
      - operator: "Exists"
        key: cloud.google.com/impending-node-termination
      volumes:
        {{- if $root.Values.network.gibVersion }}
        - name: gib
          emptyDir: {}
        {{- end }}
        - name: serving-configuration
          configMap:
            name: "{{.Release.Name}}-config"
            items:
            - key: serving-configuration
              path: {{ $root.Values.workload.configFile | default "serving-args" }}
        - name: serving-launcher
          configMap:
            name: "{{.Release.Name}}-launcher"
            defaultMode: 0700
        - name: shared-memory
          emptyDir:
            medium: "Memory"
            sizeLimit: 250Gi
        {{- range $gcs := $root.Values.volumes.gcsMounts }}
        - name: "{{ $gcs.bucketName }}"
          csi:
            driver: gcsfuse.csi.storage.gke.io
            volumeAttributes:
              bucketName: "{{ $gcs.bucketName }}"
              {{- if $gcs.mountOptions }}
              mountOptions: "{{ $gcs.mountOptions }}"
              {{- end }}
        {{- end }}
        {{- if $root.Values.volumes.ssdMountPath }}
        - name: local-ssd
          hostPath:
            path: /mnt/stateful_partition/kube-ephemeral-ssd
        {{- end }}

      initContainers:
      {{- if $root.Values.network.gibVersion }}
      - name: nccl-plugin-installer
        image: {{ $root.Values.network.gibVersion }}
        imagePullPolicy: Always
        args:
        - |
          set -ex
          /scripts/container_entry.sh install --install-nccl
          cp -R /var/lib/gib/lib64/. /target/usr/local/gib/lib64
          cp -R /var/lib/gib/. /target/usr/local/gib
        command:
        - /bin/sh
        - -c
        volumeMounts:
        - mountPath: /target/usr/local/gib
          name: gib
      {{- end }}

      containers:
        {{- if $root.Values.workload.gcsSidecarImage }}
        - name: gke-gcsfuse-sidecar
          image: {{ $root.Values.workload.gcsSidecarImage }}
        - name: gke-gcsfuse-metadata-prefetch
          image: {{ $root.Values.workload.gcsSidecarImage }}
        {{- end }}
        - name: serving
          image: "{{ $root.Values.workload.image }}"
          imagePullPolicy: Always
          {{- if $root.Values.network.hostNetwork }}
          securityContext:
            privileged: true
          {{- end }}
          env:
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: "{{ $root.Values.huggingface.secretName }}"
                  key: "{{ $root.Values.huggingface.secretData.token }}"
            # Pass NCCL settings to the container
            {{- if $root.Values.network.ncclSettings }}
            {{- toYaml .Values.network.ncclSettings | nindent 12 }}
            {{- end }}
            - name: NCCL_PLUGIN_PATH
              value: /usr/local/gib/lib64
            - name: LD_LIBRARY_PATH
              value: /usr/local/gib/lib64:/usr/local/nvidia/lib64
            {{- if $root.Values.network.gibVersion }}
            - name: NCCL_INIT_SCRIPT
              value: "/usr/local/gib/scripts/set_nccl_env.sh"
            {{- end }}
            # Workload specific environment variables
            - name: MODEL_NAME
              value: "{{ $root.Values.workload.model.name }}"
            - name: MODEL_DOWNLOAD_DIR
              value: "/ssd/{{ $root.Values.workload.model.name }}"
            {{- if $root.Values.workload.envs }}
            {{- toYaml .Values.workload.envs | nindent 12 }}
            {{- end }}

          workingDir: /workload
          command: ["/bin/bash", "-c"]
          args:
            - |
              #!/bin/bash

              if [[ -n "${NCCL_INIT_SCRIPT}" ]]; then
                echo "Running NCCL init script: ${NCCL_INIT_SCRIPT}"
                source ${NCCL_INIT_SCRIPT}
                env | grep NCCL
                ldconfig
              fi

              if [ ! -f "$LAUNCHER_SCRIPT" ]; then
                echo "Error: Launcher script $LAUNCHER_SCRIPT not found!"
                exit 1
              fi

              ARGS=()

              if [ -f "$SERVER_ARGS_FILE" ]; then
                echo "Loading server arguments from ConfigMap"
                while IFS=': ' read -r key value || [ -n "$key" ]; do
                  [[ -z "$key" || "$key" == \#* ]] && continue
                  key=$(echo "$key" | xargs)
                  value=$(echo "$value" | xargs)

                  if [ -n "$key" ]; then
                    # Handle boolean values
                    if [[ "$value" == "true" ]]; then
                      # For true values, just add the flag without a value
                      ARGS+=("--$key")
                    elif [[ "$value" == "false" ]]; then
                      ARGS+=("--$key" "false")
                    elif [ -n "$value" ]; then
                      # For non-boolean values, add both the flag and its value
                      ARGS+=("--$key" "$value")
                    else
                      ARGS+=("--$key")
                    fi
                  fi
                done < "$SERVER_ARGS_FILE"
              fi

              {{ if eq $root.Values.workload.framework "trtllm" }}
              {{- range $root.Values.workload.benchmarks.experiments }}
              echo "Running: $LAUNCHER_SCRIPT --model_name $MODEL_NAME --isl {{ .isl }} --osl {{ .osl }} --num_requests {{ .num_requests }} -- ${ARGS[@]}"
              exec "$LAUNCHER_SCRIPT" --model_name $MODEL_NAME --isl {{ .isl }} --osl {{ .osl }} --num_requests {{ .num_requests }} -- "${ARGS[@]}"
              {{- end }}
              {{ else }}
              echo "Running: $LAUNCHER_SCRIPT ${ARGS[@]}"
              exec "$LAUNCHER_SCRIPT" "${ARGS[@]}"
              {{- end }}

          volumeMounts:
            {{- if $root.Values.network.gibVersion }}
            - name: gib
              mountPath: /usr/local/gib
            {{- end }}
            - name: serving-configuration
              mountPath: {{ $root.Values.workload.configPath | default "/workload/configs" }}
            - name: serving-launcher
              mountPath: /workload/launcher
            - name: shared-memory
              mountPath: /dev/shm
            {{- range $gcs := $root.Values.volumes.gcsMounts }}
            - name: "{{ $gcs.bucketName }}"
              mountPath: "{{ $gcs.mountPath }}"
            {{- end }}
            {{- if $root.Values.volumes.ssdMountPath }}
            - name: local-ssd
              mountPath: "{{ $root.Values.volumes.ssdMountPath }}"
            {{- end }}

          resources:
            requests:
              nvidia.com/gpu: {{ $gpusPerNode }}
            limits:
              nvidia.com/gpu: {{ $gpusPerNode }}