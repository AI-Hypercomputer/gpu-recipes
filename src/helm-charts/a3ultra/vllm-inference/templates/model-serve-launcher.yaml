# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

{{ $nodes := div .Values.job.gpus 8 | max 1 }}
{{ $gpusPerNode := min .Values.job.gpus 8 }}

{{- $root := . -}}

apiVersion: apps/v1
kind: Deployment

metadata:
  name: {{ .Release.Name }}-serving
  labels:
    app: {{ .Release.Name }}-serving
spec:
  replicas: {{ $nodes }}
  selector:
    matchLabels:
      app: {{ .Release.Name }}-serving
  template:
    metadata:
      labels:
        app: {{ .Release.Name }}-serving
      annotations:
        kubectl.kubernetes.io/default-container: serving

        {{- if .Values.volumes.gcsMounts }}
        gke-gcsfuse/volumes: "true"
        gke-gcsfuse/cpu-limit: "0"
        gke-gcsfuse/memory-limit: "0"
        gke-gcsfuse/ephemeral-storage-limit: "0"
        {{- end}}
        {{- if not $root.Values.network.hostNetwork }}
        networking.gke.io/default-interface: "eth0"
        networking.gke.io/interfaces: |
        {{- if $root.Values.network.subnetworks }}
          [
            {{- range $i, $subnetwork := $root.Values.network.subnetworks }}
            {"interfaceName":"eth{{ $i }}","network":"{{ $subnetwork }}"}{{ eq $i 9 | ternary "" ","}}
            {{- end }}
          ]
        {{- else }}
          [
            {"interfaceName":"eth0","network":"default"},
            {"interfaceName":"eth1","network":"gvnic-1"},
            {{- range  $i := until 8 }}
            {"interfaceName":"eth{{ add 2 $i }}","network":"rdma-{{ $i }}"}{{ eq $i 7 | ternary "" ","}}
            {{- end }}
          ]
        {{- end }}
        {{- end }}

    spec:
      {{- if $root.Values.network.hostNetwork }}
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      {{- end }}
      restartPolicy: Always

      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
      - key: cloud.google.com/impending-node-termination
        operator: Exists
      volumes:
        - name: library-dir-host
          hostPath:
            path: /home/kubernetes/bin/nvidia
        - name: gib
          hostPath:
            path: /home/kubernetes/bin/gib
        - name: shared-memory
          emptyDir:
            medium: "Memory"
            sizeLimit: 250Gi
        - name: local-ssd
          hostPath:
            path: /mnt/stateful_partition/kube-ephemeral-ssd
        {{- range $gcs := .Values.volumes.gcsMounts }}
        - name: "{{ $gcs.bucketName }}"
          csi:
            driver: gcsfuse.csi.storage.gke.io
            volumeAttributes:
              bucketName: "{{ $gcs.bucketName }}"
        {{- end }}

      containers:
      - name: serving
        image: "{{ .Values.job.image.repository }}:{{ .Values.job.image.tag }}"
        imagePullPolicy: Always
        securityContext:
          privileged: true
        resources:
          requests:
            nvidia.com/gpu: {{ $gpusPerNode }}
          limits:
            nvidia.com/gpu: {{ $gpusPerNode }}

        env:
          - name: HF_TOKEN
            valueFrom:
              secretKeyRef:
                name: "{{ .Values.huggingface.secretName }}"
                key: "{{ .Values.huggingface.secretData.token }}"

          # Enable faster downloads of model weights from HuggingFace
          - name: HF_HUB_ENABLE_HF_TRANSFER
            value: "1"
          - name: LD_LIBRARY_PATH
            value: "/usr/local/nvidia/lib64"
          - name: NCCL_DEBUG
            value: "INFO"
          # Workload specific environment variables
          - name: MODEL_DOWNLOAD_DIR
            value: "/ssd/{{ .Values.model.name }}"

          {{- range $gcs := $root.Values.volumes.gcsMounts }}
          - name: GCS_FUSE_BUCKET
            value: "{{ $gcs.bucketName }}"
          {{- end }}

        workingDir: /vllm-workspace
        command: ["/bin/bash", "-c"]
        args:
          - |
            #!/bin/bash

            # Set recommended NCCL environment variables
            source /usr/local/gib/scripts/set_nccl_env.sh

            # Launch the server
            vllm serve deepseek-ai/DeepSeek-R1 --trust-remote-code --tensor-parallel-size 8

        volumeMounts:
          - name: library-dir-host
            mountPath: /usr/local/nvidia
          - name: gib
            mountPath: /usr/local/gib
          - name: shared-memory
            mountPath: /dev/shm
          - name: local-ssd
            mountPath: {{ .Values.volumes.ssdMountPath }}
          {{- range $gcs := .Values.volumes.gcsMounts }}
          - name: "{{ $gcs.bucketName }}"
            mountPath: "{{ $gcs.mountPath }}"
          {{- end }}